{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f069efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 14:02:19.973430: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-03 14:03:52.055415: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/gcc-8.2.0/lib64/\n",
      "2024-03-03 14:03:52.055835: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/gcc-8.2.0/lib64/\n",
      "2024-03-03 14:03:52.055856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Running UniTVelo 0.2.5)\n",
      "2024-03-03 14:04:48\n"
     ]
    }
   ],
   "source": [
    "import anndata\n",
    "import numpy as np\n",
    "import scvelo as scv\n",
    "import scanpy as sc\n",
    "import sys\n",
    "import torch\n",
    "import os.path\n",
    "sys.path.append('/nfs/team283/aa16/VeloVAE/')\n",
    "import velovae as vv\n",
    "import pickle as pickle\n",
    "from eval_utils import cross_boundary_correctness\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import unitvelo as utv\n",
    "from os.path import exists\n",
    "method = 'VeloVAE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc431cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['MouseErythroid', 'Pancreas_with_cc', 'HumanBoneMarrow', 'HumanDevelopingBrain', 'DentateGyrus' , 'MouseBoneMarrow']\n",
    "data_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_datasets/'\n",
    "save_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_results_revision/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c86cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MouseErythroid\n",
      "Filtered out 47456 genes that are detected 20 counts (shared).\n",
      "Normalized count data: X, spliced, unspliced.\n",
      "Extracted 3000 highly variable genes.\n",
      "Logarithmized X.\n",
      "computing neighbors\n",
      "    finished (0:00:34) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:03) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "Initialization using the steady-state and dynamical models.\n",
      "Gaussian Prior.\n",
      "--------------------------- Train a VeloVAE ---------------------------\n",
      "*********        Creating Training/Validation Datasets        *********\n",
      "*********                      Finished.                      *********\n",
      "*********                 Creating optimizers                 *********\n",
      "*********                      Finished.                      *********\n",
      "*********                    Start training                   *********\n",
      "*********                      Stage  1                       *********\n",
      "Total Number of Iterations Per Epoch: 54, test iteration: 106\n",
      "Epoch 1: Train ELBO = -5198.990, Test ELBO = -710268.875, \t Total Time =   0 h :  0 m : 15 s\n",
      "Epoch 100: Train ELBO = 2885.750, Test ELBO = 2849.776, \t Total Time =   0 h :  2 m : 11 s\n",
      "Epoch 200: Train ELBO = 3022.861, Test ELBO = 3019.004, \t Total Time =   0 h :  4 m :  7 s\n",
      "*********       Stage 1: Early Stop Triggered at epoch 236.       *********\n",
      "*********                      Stage  2                       *********\n",
      "Cell-wise KNN Estimation.\n",
      "Percentage of Invalid Sets: 0.004\n",
      "Average Set Size: 207\n",
      "Finished. Actual Time:   0 h :  0 m : 13 s\n",
      "Epoch 237: Train ELBO = 2910.209, Test ELBO = 2535.164, \t Total Time =   0 h :  5 m :  4 s\n",
      "Epoch 300: Train ELBO = 3013.839, Test ELBO = 2988.081, \t Total Time =   0 h :  6 m : 27 s\n",
      "*********       Stage 2: Early Stop Triggered at epoch 303.       *********\n",
      "*********              Finished. Total Time =   0 h :  6 m : 31 s             *********\n",
      "computing neighbors\n",
      "    finished (0:00:05) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing velocities\n",
      "    finished (0:00:03) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "computing velocity graph (using 1/64 cores)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c013c7d1c09a49cd8a8408645e8a873b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9815 [00:00<?, ?cells/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:22) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "computing velocity embedding\n",
      "    finished (0:00:03) --> added\n",
      "    'velocity_umap', embedded velocity vectors (adata.obsm)\n",
      "# Cross-Boundary Direction Correctness (A->B)\n",
      "{('Blood progenitors 1', 'Blood progenitors 2'): 0.4143223510967928, ('Blood progenitors 2', 'Erythroid1'): 0.24962148183575375, ('Erythroid1', 'Erythroid2'): 0.2391521645082725, ('Erythroid2', 'Erythroid3'): -0.46603091358517107}\n",
      "Total Mean: 0.10926627096391199\n",
      "# In-cluster Coherence\n",
      "{'Blood progenitors 1': 0.80518085, 'Blood progenitors 2': 0.7254092, 'Erythroid1': 0.67482334, 'Erythroid2': 0.68407726, 'Erythroid3': 0.8362193}\n",
      "Total Mean: 0.7451419830322266\n",
      "Pancreas_with_cc\n",
      "Filtered out 20801 genes that are detected 20 counts (shared).\n",
      "Normalized count data: X, spliced, unspliced.\n",
      "Extracted 3000 highly variable genes.\n",
      "Logarithmized X.\n",
      "computing neighbors\n",
      "    finished (0:00:02) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:01) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "Initialization using the steady-state and dynamical models.\n",
      "Error in callback <function flush_figures at 0x1482f8fd4a60> (for post_execute):\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    adata = sc.read_h5ad(data_dir + dataset + '/' + dataset + '_anndata.h5ad')\n",
    "    start = time.time()\n",
    "    scv.pp.filter_and_normalize(adata, min_shared_counts=20, n_top_genes=3000)\n",
    "    scv.pp.moments(adata, n_pcs=30, n_neighbors=30)\n",
    "    torch.manual_seed(2022)\n",
    "    np.random.seed(2022)\n",
    "    full_vb = vv.VAEFullVB(adata, tmax=20, dim_z=5, device='cuda:0')\n",
    "    full_vb.train(adata, plot=True, embed=\"umap\")\n",
    "    end = time.time()\n",
    "    scv.pp.neighbors(adata)\n",
    "    scv.tl.velocity_graph(adata, vkey = 'velocity')\n",
    "    scv.tl.velocity_embedding(adata, vkey = 'velocity')\n",
    "    fix, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
    "    scv.pl.velocity_embedding_stream(adata, basis='umap', save = False, vkey='velocity',\n",
    "                                     show = False, ax = ax)\n",
    "    plt.savefig(save_dir + 'UMAPs/' + dataset + '_UMAP_VeloVAE.svg')\n",
    "    # Calculate performance metrics:\n",
    "    file = open(data_dir + dataset + '/' + dataset + '_groundTruth.pickle' ,'rb')\n",
    "    ground_truth = pickle.load(file)\n",
    "    metrics = utv.evaluate(adata, ground_truth, 'clusters', 'velocity')\n",
    "    if exists(save_dir + dataset + '_CBDC_scores.csv'):\n",
    "        tab = pd.read_csv(save_dir + dataset + '_CBDC_scores.csv', index_col = 0)\n",
    "    else:\n",
    "        tab = pd.DataFrame(columns = list(metrics['Cross-Boundary Direction Correctness (A->B)'].keys()) + ['Mean', 'Time'],\n",
    "                 index = [method])\n",
    "    cb_score = [np.mean(metrics['Cross-Boundary Direction Correctness (A->B)'][x])\n",
    "                for x in metrics['Cross-Boundary Direction Correctness (A->B)'].keys()]\n",
    "    tab.loc[method,:] = cb_score + [np.mean(cb_score), end-start]\n",
    "    tab.to_csv(save_dir + dataset + '_CBDC_scores.csv')\n",
    "    plt.savefig(save_dir + 'UMAPs/' + dataset + '_UMAP_' + method + '.svg')\n",
    "    adata.write_h5ad('/nfs/team283/aa16/data/fate_benchmarking/' + method + dataset + 'AnnDataForCellRank.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96cb98c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:VeloVAE_env]",
   "language": "python",
   "name": "conda-env-VeloVAE_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
