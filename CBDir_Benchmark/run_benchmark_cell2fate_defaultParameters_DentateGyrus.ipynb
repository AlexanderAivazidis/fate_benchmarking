{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5023c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Running UniTVelo 0.2.5.2)\n",
      "2024-02-07 18:31:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 18:31:25.090142: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-07 18:31:25.090202: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-07 18:31:25.135558: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping at most 100000 cells per cluster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 10340 genes that are detected 20 counts (shared).\n",
      "Extracted 3000 highly variable genes.\n",
      "Leiden clustering ...\n",
      "WARNING: You’re trying to run this on 507 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n",
      "         Falling back to preprocessing with `sc.pp.pca` and default params.\n",
      "Number of Leiden Clusters: 14\n",
      "Maximal Number of Modules: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: 100%|██████████████████████████████████████████████████████████████████████████| 500/500 [07:36<00:00,  1.10it/s, v_num=1, elbo_train=6.74e+6]\n",
      "Sampling local variables, batch: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:12<00:00, 12.62s/it]\n",
      "Sampling global variables, sample: 100%|█████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:09<00:00,  3.03it/s]\n",
      "Warning: Saving ALL posterior samples. Specify \"return_samples: False\" to save just summary statistics.\n",
      "Computing total RNAvelocity ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "import scvelo as scv\n",
    "import scanpy as sc\n",
    "import cell2fate as c2f\n",
    "import pickle as pickle\n",
    "from eval_utils import cross_boundary_correctness\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import unitvelo as utv\n",
    "import time\n",
    "\n",
    "method = 'cell2fate'\n",
    "datasets = datasets = ['Pancreas_with_cc', 'DentateGyrus' , 'MouseErythroid', 'MouseBoneMarrow', 'HumanBoneMarrow', 'HumanDevelopingBrain']\n",
    "batch_id = [None, None, 'sequencing.batch', None, None, 'Sanger_sample_ID']\n",
    "Tmax_prior_mean = [50., 50., 50., 50., 500., 50.]\n",
    "Tmax_prior_sd = [50., 50., 50., 50., 100., 50.]\n",
    "data_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_datasets/'\n",
    "save_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_results_revision/'\n",
    "\n",
    "i = 1\n",
    "dataset = datasets[i]\n",
    "adata = sc.read_h5ad(data_dir + dataset + '/' + dataset + '_anndata.h5ad')\n",
    "start = time.time()\n",
    "adata = c2f.utils.get_training_data(adata, cells_per_cluster = 10**5, cluster_column = 'clusters',\n",
    "                                remove_clusters = [], min_shared_counts = 20, n_var_genes= 3000)\n",
    "if batch_id[i]:\n",
    "    c2f.Cell2fate_DynamicalModel.setup_anndata(adata, spliced_label='spliced', unspliced_label='unspliced',\n",
    "                                          batch_key = batch_id[i])\n",
    "else:\n",
    "    c2f.Cell2fate_DynamicalModel.setup_anndata(adata, spliced_label='spliced', unspliced_label='unspliced')    \n",
    "n_modules = c2f.utils.get_max_modules(adata)\n",
    "mod = c2f.Cell2fate_DynamicalModel(adata, n_modules = n_modules,\n",
    "                                   Tmax_prior={\"mean\": Tmax_prior_mean[i], \"sd\": Tmax_prior_sd[i]})\n",
    "mod.train()\n",
    "adata = mod.export_posterior(adata)\n",
    "end = time.time()\n",
    "mod.compute_and_plot_total_velocity(adata, save = False, delete = False)\n",
    "# Calculate performance metrics:\n",
    "file = open(data_dir + dataset + '/' + dataset + '_groundTruth.pickle' ,'rb')\n",
    "ground_truth = pickle.load(file)\n",
    "metrics = utv.evaluate(adata, ground_truth, 'clusters', 'Velocity')\n",
    "if exists(save_dir + dataset + '_CBDC_scores.csv'):\n",
    "    tab = pd.read_csv(save_dir + dataset + '_CBDC_scores.csv', index_col = 0)\n",
    "else:\n",
    "    tab = pd.DataFrame(columns = list(metrics['Cross-Boundary Direction Correctness (A->B)'].keys()) + ['Mean', 'Time'],\n",
    "             index = [method])\n",
    "cb_score = [np.mean(metrics['Cross-Boundary Direction Correctness (A->B)'][x])\n",
    "            for x in metrics['Cross-Boundary Direction Correctness (A->B)'].keys()]\n",
    "tab.loc[method,:] = cb_score + [np.mean(cb_score), end-start]\n",
    "tab.to_csv(save_dir + dataset + '_CBDC_scores.csv')\n",
    "fix, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
    "scv.pl.velocity_embedding_stream(adata, basis='umap', save = False, vkey='Velocity',\n",
    "                                 show = False, ax = ax)\n",
    "plt.savefig(save_dir + 'UMAPs/' + dataset + '_UMAP_' + method + '.svg')\n",
    "adata.layers['velocity'] = np.array(adata.layers['Velocity'])\n",
    "del adata.layers['Velocity']\n",
    "adata.layers['Ms'] = mod.samples['post_sample_means']['mu_expression'][...,0]\n",
    "adata.layers['Mu'] = mod.samples['post_sample_means']['mu_expression'][...,1]\n",
    "adata.write_h5ad('/nfs/team283/aa16/data/fate_benchmarking/' + method + dataset + 'AnnDataForCellRank.h5ad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cell2fate_env]",
   "language": "python",
   "name": "conda-env-cell2fate_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
