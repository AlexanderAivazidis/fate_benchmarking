{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3792e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Running UniTVelo 0.2.5.2)\n",
      "2024-03-09 15:56:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 15:56:17.643776: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-09 15:56:17.643828: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-09 15:56:17.645735: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping at most 1000000 cells per cluster\n",
      "Filtered out 10340 genes that are detected 20 counts (shared).\n",
      "Extracted 3000 highly variable genes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leiden clustering ...\n",
      "WARNING: You’re trying to run this on 507 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n",
      "         Falling back to preprocessing with `sc.pp.pca` and default params.\n",
      "Number of Leiden Clusters: 14\n",
      "Maximal Number of Modules: 16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/500:  38%|████████████████████████████▌                                              | 190/500 [03:21<05:21,  1.04s/it, v_num=1, elbo_train=6.8e+6]"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.chdir('..')\n",
    "# os.chdir('..')\n",
    "import scvelo as scv\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import pickle as pickle\n",
    "from eval_utils import cross_boundary_correctness\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import unitvelo as utv\n",
    "import cell2fate as c2f\n",
    "method = 'Cell2fateDynamicalModel_DentateGyrus_RobustnessAnalysis'\n",
    "data_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_datasets/'\n",
    "save_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_results/DentateGyrus_Robustness/'\n",
    "dataset = 'DentateGyrus'\n",
    "n_genes_array = np.array((1000, 2000, 3000, 4000, 5000))\n",
    "min_counts = 20\n",
    "Tmax_mean_array = np.array((50., 12., 25., 100., 200.))\n",
    "Tmax_sd_array = np.array((12., 25., 50., 100., 200.))\n",
    "module_multiplication = np.array((0.85, 1.0, 1.15, 1.3, 1.45))\n",
    "\n",
    "j = 0\n",
    "i = 0\n",
    "l = 2\n",
    "k = 2\n",
    "for j in range(len(Tmax_mean_array)):\n",
    "    n_genes = n_genes_array[k]\n",
    "    Tmax_mean = Tmax_mean_array[j]\n",
    "    module_factor = module_multiplication[l]\n",
    "    save_name = method + '_TmaxMeanOnly_' + str(j)\n",
    "#     if exists(save_dir + save_name + '.pickle'):\n",
    "#         continue\n",
    "    adata = sc.read_h5ad(data_dir + dataset + '/' + dataset + '_anndata.h5ad')\n",
    "    adata = c2f.utils.get_training_data(adata, cells_per_cluster = 10**6, cluster_column = 'clusters',\n",
    "                                    remove_clusters = [], min_shared_counts = min_counts, n_var_genes= n_genes)\n",
    "    c2f.Cell2fate_DynamicalModel.setup_anndata(adata,\n",
    "                                               spliced_label='spliced', unspliced_label='unspliced')    \n",
    "    n_modules = int(np.round((c2f.utils.get_max_modules(adata)/1.15*module_factor)))\n",
    "    print(n_modules)\n",
    "    mod = c2f.Cell2fate_DynamicalModel(adata,\n",
    "                                       n_modules = n_modules,\n",
    "                                      Tmax_prior={\"mean\": Tmax_mean, \"sd\": 50.0})\n",
    "    from cell2fate._pyro_mixin import PyroTrainingPlan_ClippedAdamDecayingRate\n",
    "    mod.train(**{'training_plan' : PyroTrainingPlan_ClippedAdamDecayingRate})\n",
    "    sample_kwarg = {\"num_samples\": 10, \"batch_size\" : adata.n_obs,\n",
    "         \"use_gpu\" : True, 'return_samples': False}\n",
    "    adata = mod.export_posterior(adata, sample_kwargs = sample_kwarg)\n",
    "    post_sample_means = mod.samples['post_sample_means']\n",
    "    post_sample_means['var_names'] = adata.var_names\n",
    "    post_sample_means['obs_names'] = adata.obs_names\n",
    "    post_sample_means['clusters'] = adata.obs['clusters']\n",
    "    post_sample_means['ELBO'] = np.mean(np.array(mod.history['elbo_train'][-45:]))\n",
    "    mod.compute_and_plot_total_velocity_scvelo(adata, save = save_dir + save_name + '.jpg', delete = False)\n",
    "    # Calculate performance metrics:\n",
    "    file = open(data_dir + dataset + '/' + dataset + '_groundTruth.pickle' ,'rb')\n",
    "    ground_truth = pickle.load(file)\n",
    "    metrics = utv.evaluate(adata, ground_truth, 'clusters', 'velocity')\n",
    "    for x in metrics['Cross-Boundary Direction Correctness (A->B)'].keys():\n",
    "        metrics['Cross-Boundary Direction Correctness (A->B)'][x] = np.mean(metrics['Cross-Boundary Direction Correctness (A->B)'][x])\n",
    "    post_sample_means['CBDC'] = metrics['Cross-Boundary Direction Correctness (A->B)']\n",
    "    with open(save_dir + save_name + '.pickle', 'wb') as handle:\n",
    "        pickle.dump(post_sample_means, handle, protocol=pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0885cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import os\n",
    "# # os.chdir('..')\n",
    "# # os.chdir('..')\n",
    "# import scvelo as scv\n",
    "# import scanpy as sc\n",
    "# import scvi\n",
    "# import pickle as pickle\n",
    "# from eval_utils import cross_boundary_correctness\n",
    "# from datetime import datetime\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from os.path import exists\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "# import unitvelo as utv\n",
    "# import cell2fate as c2f\n",
    "# method = 'Cell2fateDynamicalModel_DentateGyrus_RobustnessAnalysis'\n",
    "# data_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_datasets/'\n",
    "# save_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_results/DentateGyrus_Robustness/'\n",
    "# dataset = 'DentateGyrus'\n",
    "# n_genes_array = np.array((1000, 2000, 3000, 4000, 5000))\n",
    "# min_counts = 10\n",
    "# Tmax_mean_array = np.array((12., 25., 50., 100., 200.))\n",
    "# Tmax_sd_array = np.array((12., 25., 50., 100., 200.))\n",
    "# module_multiplication = np.array((0.85, 1.0, 1.15, 1.3, 1.45))\n",
    "\n",
    "# j = 0\n",
    "# i = 0\n",
    "# l = 2\n",
    "# k = 2\n",
    "# for j in range(len(Tmax_mean_array)):\n",
    "#     n_genes = n_genes_array[k]\n",
    "#     Tmax_sd = Tmax_sd_array[j]\n",
    "#     module_factor = module_multiplication[l]\n",
    "#     save_name = method + '_TmaxSDOnly_' + str(j)\n",
    "#     if exists(save_dir + save_name + '.pickle'):\n",
    "#         continue\n",
    "#     adata = sc.read_h5ad(data_dir + dataset + '/' + dataset + '_anndata.h5ad')\n",
    "#     adata = c2f.utils.get_training_data(adata, cells_per_cluster = 10**6, cluster_column = 'clusters',\n",
    "#                                     remove_clusters = [], min_shared_counts = min_counts, n_var_genes= n_genes)\n",
    "#     c2f.Cell2fate_DynamicalModel.setup_anndata(adata,\n",
    "#                                                spliced_label='spliced', unspliced_label='unspliced')    \n",
    "#     n_modules = int(np.round((c2f.utils.get_max_modules(adata)/1.15*module_factor)))\n",
    "#     mod = c2f.Cell2fate_DynamicalModel(adata,\n",
    "#                                        n_modules = n_modules,\n",
    "#                                       Tmax_prior={\"mean\": 50.0, \"sd\": Tmax_sd})\n",
    "#     from cell2fate._pyro_mixin import PyroTrainingPlan_ClippedAdamDecayingRate\n",
    "#     mod.train(**{'training_plan' : PyroTrainingPlan_ClippedAdamDecayingRate})\n",
    "#     sample_kwarg = {\"num_samples\": 10, \"batch_size\" : adata.n_obs,\n",
    "#          \"use_gpu\" : True, 'return_samples': False}\n",
    "#     adata = mod.export_posterior(adata, sample_kwargs = sample_kwarg)\n",
    "#     post_sample_means = mod.samples['post_sample_means']\n",
    "#     post_sample_means['var_names'] = adata.var_names\n",
    "#     post_sample_means['obs_names'] = adata.obs_names\n",
    "#     post_sample_means['clusters'] = adata.obs['clusters']\n",
    "#     post_sample_means['ELBO'] = np.mean(np.array(mod.history['elbo_train'][-45:]))\n",
    "#     mod.compute_and_plot_total_velocity_scvelo(adata, save = save_dir + save_name + '.jpg', delete = False)\n",
    "#     # Calculate performance metrics:\n",
    "#     file = open(data_dir + dataset + '/' + dataset + '_groundTruth.pickle' ,'rb')\n",
    "#     ground_truth = pickle.load(file)\n",
    "#     metrics = utv.evaluate(adata, ground_truth, 'clusters', 'velocity')\n",
    "#     for x in metrics['Cross-Boundary Direction Correctness (A->B)'].keys():\n",
    "#         metrics['Cross-Boundary Direction Correctness (A->B)'][x] = np.mean(metrics['Cross-Boundary Direction Correctness (A->B)'][x])\n",
    "#     post_sample_means['CBDC'] = metrics['Cross-Boundary Direction Correctness (A->B)']\n",
    "#     with open(save_dir + save_name + '.pickle', 'wb') as handle:\n",
    "#         pickle.dump(post_sample_means, handle, protocol=pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56289b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cell2fate_env]",
   "language": "python",
   "name": "conda-env-cell2fate_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
