{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd5023c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('..')\n",
    "# import scvelo as scv\n",
    "# import scanpy as sc\n",
    "# import cell2fate as c2f\n",
    "# import pickle as pickle\n",
    "# from eval_utils import cross_boundary_correctness\n",
    "# from datetime import datetime\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from os.path import exists\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "# import unitvelo as utv\n",
    "# import time\n",
    "# import pickle\n",
    "\n",
    "# method = 'cell2fate'\n",
    "# datasets = datasets = ['Pancreas_with_cc', 'DentateGyrus' , 'MouseErythroid', 'MouseBoneMarrow', 'HumanBoneMarrow', 'HumanDevelopingBrain']\n",
    "# batch_id = [None, None, 'sequencing.batch', None, None, 'Sanger_sample_ID']\n",
    "# Tmax_prior_mean = [50., 50., 50., 50., 500., 50.]\n",
    "# Tmax_prior_sd = [50., 50., 50., 50., 100., 50.]\n",
    "# data_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_datasets/'\n",
    "# save_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_results_revision/'\n",
    "\n",
    "# multiplication_factor = (1., 0.25, 0.5, 2., 4.)\n",
    "# for i in range(len(multiplication_factor)):\n",
    "#     print(i)\n",
    "#     filename = '/nfs/team283/aa16/data/fate_benchmarking/SimulatedData/Beta' + str(multiplication_factor[i]) + '.pickle'\n",
    "#     with open(filename, 'rb') as handle:\n",
    "#         data = pickle.load(handle)    \n",
    "#     dataset = datasets[1]\n",
    "#     adata = sc.read_h5ad(data_dir + dataset + '/' + dataset + '_anndata.h5ad')\n",
    "#     adata = c2f.utils.get_training_data(adata, cells_per_cluster = 10**5, cluster_column = 'clusters',\n",
    "#                                     remove_clusters = [], min_shared_counts = 20, n_var_genes= 3000)\n",
    "#     adata.layers['spliced'] = np.array(data[...,1])\n",
    "#     adata.layers['unspliced'] = np.array(data[...,0])\n",
    "#     if batch_id[i]:\n",
    "#         c2f.Cell2fate_DynamicalModel.setup_anndata(adata, spliced_label='spliced', unspliced_label='unspliced',\n",
    "#                                               batch_key = batch_id[1])\n",
    "#     else:\n",
    "#         c2f.Cell2fate_DynamicalModel.setup_anndata(adata, spliced_label='spliced', unspliced_label='unspliced')    \n",
    "#     n_modules = 16\n",
    "#     mod = c2f.Cell2fate_DynamicalModel(adata, n_modules = n_modules,\n",
    "#                                        Tmax_prior={\"mean\": Tmax_prior_mean[1], \"sd\": Tmax_prior_sd[1]})\n",
    "#     mod.train()\n",
    "#     adata = mod.export_posterior(adata)\n",
    "#     posterior = mod.samples['post_sample_means']\n",
    "#     with open('/nfs/team283/aa16/data/fate_benchmarking/SimulatedData/cell2fatePosterior_Beta' + str(multiplication_factor[i]) + '.pickle', 'wb') as handle:\n",
    "#         pickle.dump(posterior, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a63fa8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('..')\n",
    "# import scvelo as scv\n",
    "# import scanpy as sc\n",
    "# import cell2fate as c2f\n",
    "# import pickle as pickle\n",
    "# from eval_utils import cross_boundary_correctness\n",
    "# from datetime import datetime\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from os.path import exists\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "# import unitvelo as utv\n",
    "# import time\n",
    "# import pickle\n",
    "\n",
    "# method = 'cell2fate'\n",
    "# datasets = datasets = ['Pancreas_with_cc', 'DentateGyrus' , 'MouseErythroid', 'MouseBoneMarrow', 'HumanBoneMarrow', 'HumanDevelopingBrain']\n",
    "# batch_id = [None, None, 'sequencing.batch', None, None, 'Sanger_sample_ID']\n",
    "# Tmax_prior_mean = [50., 50., 50., 50., 500., 50.]\n",
    "# Tmax_prior_sd = [50., 50., 50., 50., 100., 50.]\n",
    "# data_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_datasets/'\n",
    "# save_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_results_revision/'\n",
    "\n",
    "# multiplication_factor = (1., 0.25, 0.5, 2., 4.)\n",
    "# for i in range(len(multiplication_factor)):\n",
    "#     print(i)\n",
    "#     filename = '/nfs/team283/aa16/data/fate_benchmarking/SimulatedData/Gamma' + str(multiplication_factor[i]) + '.pickle'\n",
    "#     with open(filename, 'rb') as handle:\n",
    "#         data = pickle.load(handle)    \n",
    "#     dataset = datasets[1]\n",
    "#     adata = sc.read_h5ad(data_dir + dataset + '/' + dataset + '_anndata.h5ad')\n",
    "#     adata = c2f.utils.get_training_data(adata, cells_per_cluster = 10**5, cluster_column = 'clusters',\n",
    "#                                     remove_clusters = [], min_shared_counts = 20, n_var_genes= 3000)\n",
    "#     adata.layers['spliced'] = np.array(data[...,1])\n",
    "#     adata.layers['unspliced'] = np.array(data[...,0])\n",
    "#     if batch_id[i]:\n",
    "#         c2f.Cell2fate_DynamicalModel.setup_anndata(adata, spliced_label='spliced', unspliced_label='unspliced',\n",
    "#                                               batch_key = batch_id[1])\n",
    "#     else:\n",
    "#         c2f.Cell2fate_DynamicalModel.setup_anndata(adata, spliced_label='spliced', unspliced_label='unspliced')    \n",
    "#     n_modules = 16\n",
    "#     mod = c2f.Cell2fate_DynamicalModel(adata, n_modules = n_modules,\n",
    "#                                        Tmax_prior={\"mean\": Tmax_prior_mean[1], \"sd\": Tmax_prior_sd[1]})\n",
    "#     mod.train()\n",
    "#     adata = mod.export_posterior(adata)\n",
    "#     posterior = mod.samples['post_sample_means']\n",
    "#     with open('/nfs/team283/aa16/data/fate_benchmarking/SimulatedData/cell2fatePosterior_Gamma' + str(multiplication_factor[i]) + '.pickle', 'wb') as handle:\n",
    "#         pickle.dump(posterior, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3558a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('..')\n",
    "# import scvelo as scv\n",
    "# import scanpy as sc\n",
    "# import cell2fate as c2f\n",
    "# import pickle as pickle\n",
    "# from eval_utils import cross_boundary_correctness\n",
    "# from datetime import datetime\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from os.path import exists\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "# import unitvelo as utv\n",
    "# import time\n",
    "# import pickle\n",
    "\n",
    "# method = 'cell2fate'\n",
    "# datasets = datasets = ['Pancreas_with_cc', 'DentateGyrus' , 'MouseErythroid', 'MouseBoneMarrow', 'HumanBoneMarrow', 'HumanDevelopingBrain']\n",
    "# batch_id = [None, None, 'sequencing.batch', None, None, 'Sanger_sample_ID']\n",
    "# Tmax_prior_mean = [50., 50., 50., 50., 500., 50.]\n",
    "# Tmax_prior_sd = [50., 50., 50., 50., 100., 50.]\n",
    "# data_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_datasets/'\n",
    "# save_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_results_revision/'\n",
    "\n",
    "# multiplication_factor = (1., 0.25, 0.5, 2., 4.)\n",
    "# for i in range(len(multiplication_factor)):\n",
    "#     print(i)\n",
    "#     filename = '/nfs/team283/aa16/data/fate_benchmarking/SimulatedData/Overdispersion' + str(multiplication_factor[i]) + '.pickle'\n",
    "#     with open(filename, 'rb') as handle:\n",
    "#         data = pickle.load(handle)    \n",
    "#     dataset = datasets[1]\n",
    "#     adata = sc.read_h5ad(data_dir + dataset + '/' + dataset + '_anndata.h5ad')\n",
    "#     adata = c2f.utils.get_training_data(adata, cells_per_cluster = 10**5, cluster_column = 'clusters',\n",
    "#                                     remove_clusters = [], min_shared_counts = 20, n_var_genes= 3000)\n",
    "#     adata.layers['spliced'] = np.array(data[...,1])\n",
    "#     adata.layers['unspliced'] = np.array(data[...,0])\n",
    "#     if batch_id[i]:\n",
    "#         c2f.Cell2fate_DynamicalModel.setup_anndata(adata, spliced_label='spliced', unspliced_label='unspliced',\n",
    "#                                               batch_key = batch_id[1])\n",
    "#     else:\n",
    "#         c2f.Cell2fate_DynamicalModel.setup_anndata(adata, spliced_label='spliced', unspliced_label='unspliced')    \n",
    "#     n_modules = 16\n",
    "#     mod = c2f.Cell2fate_DynamicalModel(adata, n_modules = n_modules,\n",
    "#                                        Tmax_prior={\"mean\": Tmax_prior_mean[1], \"sd\": Tmax_prior_sd[1]})\n",
    "#     mod.train()\n",
    "#     adata = mod.export_posterior(adata)\n",
    "#     posterior = mod.samples['post_sample_means']\n",
    "#     with open('/nfs/team283/aa16/data/fate_benchmarking/SimulatedData/cell2fatePosterior_Overdispersion' + str(multiplication_factor[i]) + '.pickle', 'wb') as handle:\n",
    "#         pickle.dump(posterior, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ace5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 17:04:51.731497: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-08 17:04:51.846518: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-08 17:04:51.846562: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-08 17:04:51.848382: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-08 17:04:51.861925: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-08 17:04:51.862927: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-08 17:04:57.057229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Running UniTVelo 0.2.5.2)\n",
      "2024-03-08 17:05:04\n",
      "0\n",
      "Keeping at most 100000 cells per cluster\n",
      "Filtered out 10340 genes that are detected 20 counts (shared).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 3000 highly variable genes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: 100%|██████████████████████████████████████████████████████████████████████████| 500/500 [09:45<00:00,  1.17s/it, v_num=1, elbo_train=6.87e+6]\n",
      "Sampling local variables, batch: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.45s/it]\n",
      "Sampling global variables, sample: 100%|█████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:10<00:00,  2.77it/s]\n",
      "Warning: Saving ALL posterior samples. Specify \"return_samples: False\" to save just summary statistics.\n",
      "1\n",
      "Keeping at most 100000 cells per cluster\n",
      "Filtered out 10340 genes that are detected 20 counts (shared).\n",
      "Extracted 3000 highly variable genes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: 100%|██████████████████████████████████████████████████████████████████████████| 500/500 [09:41<00:00,  1.16s/it, v_num=1, elbo_train=2.91e+6]\n",
      "Sampling local variables, batch: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.40s/it]\n",
      "Sampling global variables, sample: 100%|█████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:10<00:00,  2.77it/s]\n",
      "Warning: Saving ALL posterior samples. Specify \"return_samples: False\" to save just summary statistics.\n",
      "2\n",
      "Keeping at most 100000 cells per cluster\n",
      "Filtered out 10340 genes that are detected 20 counts (shared).\n",
      "Extracted 3000 highly variable genes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/500:  33%|████████████████████████▌                                                 | 166/500 [03:13<06:18,  1.13s/it, v_num=1, elbo_train=4.61e+6]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "import scvelo as scv\n",
    "import scanpy as sc\n",
    "import cell2fate as c2f\n",
    "import pickle as pickle\n",
    "from eval_utils import cross_boundary_correctness\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import unitvelo as utv\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "method = 'cell2fate'\n",
    "datasets = datasets = ['Pancreas_with_cc', 'DentateGyrus' , 'MouseErythroid', 'MouseBoneMarrow', 'HumanBoneMarrow', 'HumanDevelopingBrain']\n",
    "batch_id = [None, None, 'sequencing.batch', None, None, 'Sanger_sample_ID']\n",
    "Tmax_prior_mean = [50., 50., 50., 50., 500., 50.]\n",
    "Tmax_prior_sd = [50., 50., 50., 50., 100., 50.]\n",
    "data_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_datasets/'\n",
    "save_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_results_revision/'\n",
    "\n",
    "multiplication_factor = (1., 0.25, 0.5, 2., 4.)\n",
    "for i in range(len(multiplication_factor)):\n",
    "    print(i)\n",
    "    filename = '/nfs/team283/aa16/data/fate_benchmarking/SimulatedData/DetectionEfficiency' + str(multiplication_factor[i]) + '.pickle'\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)    \n",
    "    dataset = datasets[1]\n",
    "    adata = sc.read_h5ad(data_dir + dataset + '/' + dataset + '_anndata.h5ad')\n",
    "    adata = c2f.utils.get_training_data(adata, cells_per_cluster = 10**5, cluster_column = 'clusters',\n",
    "                                    remove_clusters = [], min_shared_counts = 20, n_var_genes= 3000)\n",
    "    adata.layers['spliced'] = np.array(data[...,1])\n",
    "    adata.layers['unspliced'] = np.array(data[...,0])\n",
    "    if batch_id[i]:\n",
    "        c2f.Cell2fate_DynamicalModel.setup_anndata(adata, spliced_label='spliced', unspliced_label='unspliced',\n",
    "                                              batch_key = batch_id[1])\n",
    "    else:\n",
    "        c2f.Cell2fate_DynamicalModel.setup_anndata(adata, spliced_label='spliced', unspliced_label='unspliced')    \n",
    "    n_modules = 16\n",
    "    mod = c2f.Cell2fate_DynamicalModel(adata, n_modules = n_modules,\n",
    "                                       Tmax_prior={\"mean\": Tmax_prior_mean[1], \"sd\": Tmax_prior_sd[1]})\n",
    "    mod.train()\n",
    "    adata = mod.export_posterior(adata)\n",
    "    posterior = mod.samples['post_sample_means']\n",
    "    with open('/nfs/team283/aa16/data/fate_benchmarking/SimulatedData/cell2fatePosterior_DetectionEfficiency' + str(multiplication_factor[i]) + '.pickle', 'wb') as handle:\n",
    "        pickle.dump(posterior, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cell2fate_env_A100]",
   "language": "python",
   "name": "conda-env-cell2fate_env_A100-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
