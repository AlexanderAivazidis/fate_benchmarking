{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5023c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvelo as scv\n",
    "import scanpy as sc\n",
    "import cell2fate as c2f\n",
    "import pickle as pickle\n",
    "import os\n",
    "os.chdir('..')\n",
    "os.chdir('..')\n",
    "from eval_utils import cross_boundary_correctness\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import unitvelo as utv\n",
    "method = 'Cell2fateDynamicalModel_batchSize128epochs250'\n",
    "data_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_datasets/'\n",
    "save_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_results/'\n",
    "datasets = ['Pancreas_with_cc',  'DentateGyrus' , 'MouseBoneMarrow', 'MouseErythroid', 'HumanBoneMarrow']\n",
    "n_genes_list = np.array((2000, 3000))\n",
    "n_counts_list = np.array((10, 20))\n",
    "\n",
    "for i in range(len(n_genes_list)):\n",
    "    for j in range(len(n_counts_list)):\n",
    "        for k in range(len(datasets)):\n",
    "            print(i)\n",
    "            print(j)\n",
    "            print(k)\n",
    "            dataset = datasets[k]\n",
    "            n_genes = n_genes_list[i]\n",
    "            min_counts = n_counts_list[j]\n",
    "            model_index = str(i) + '-' + str(j) + '-' + str(k)\n",
    "            save_name = method + '_'\n",
    "            if exists(save_dir + save_name + '_CBDC_fullBenchmark.csv'):\n",
    "                tab = pd.read_csv(save_dir + save_name + '_CBDC_fullBenchmark.csv', index_col = 0)\n",
    "                if model_index in tab.index:\n",
    "                    continue\n",
    "            adata = sc.read_h5ad(data_dir + dataset + '/' + dataset + '_anndata.h5ad')\n",
    "            adata = c2f.utils.get_training_data(adata, cells_per_cluster = 10**6, cluster_column = 'clusters',\n",
    "                                            remove_clusters = [], min_shared_counts = min_counts, n_var_genes= n_genes)\n",
    "            c2f.Cell2fate_DynamicalModel.setup_anndata(adata, spliced_label='spliced', unspliced_label='unspliced')    \n",
    "            n_modules = c2f.utils.get_max_modules(adata)\n",
    "            mod = c2f.Cell2fate_DynamicalModel(adata,\n",
    "                                               n_modules = n_modules)   \n",
    "            mod.train(batch_size = 128, max_epochs = 250)\n",
    "            sample_kwarg = {\"num_samples\": 3, \"batch_size\" : adata.n_obs,\n",
    "                 \"use_gpu\" : True, 'return_samples': False}\n",
    "            adata = mod.export_posterior(adata, sample_kwargs = sample_kwarg)\n",
    "            mod.compute_and_plot_total_velocity_scvelo(adata, save = False, delete = False)\n",
    "            # Calculate performance metrics:\n",
    "            file = open(data_dir + dataset + '/' + dataset + '_groundTruth.pickle' ,'rb')\n",
    "            ground_truth = pickle.load(file)\n",
    "            metrics = utv.evaluate(adata, ground_truth, 'clusters', 'velocity')\n",
    "            cb_score = [np.mean(metrics['Cross-Boundary Direction Correctness (A->B)'][x])\n",
    "                        for x in metrics['Cross-Boundary Direction Correctness (A->B)'].keys()]\n",
    "            if exists(save_dir + save_name + '_CBDC_fullBenchmark.csv'):\n",
    "                tab = pd.read_csv(save_dir + save_name + '_CBDC_fullBenchmark.csv', index_col = 0)\n",
    "            else:\n",
    "                c_names = ['CBDC']\n",
    "                tab = pd.DataFrame(columns = c_names)\n",
    "            tab.loc[model_index, 'CBDC'] = np.mean(cb_score)\n",
    "            tab.to_csv(save_dir + save_name + '_CBDC_fullBenchmark.csv')\n",
    "tab = pd.read_csv(save_dir + save_name + '_CBDC_fullBenchmark.csv', index_col = 0)\n",
    "tab.loc['AVERAGE', 'CBDC'] = np.mean(tab['CBDC'])\n",
    "tab.to_csv(save_dir + save_name + '_CBDC_fullBenchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc55582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cell2fate_env]",
   "language": "python",
   "name": "conda-env-cell2fate_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
