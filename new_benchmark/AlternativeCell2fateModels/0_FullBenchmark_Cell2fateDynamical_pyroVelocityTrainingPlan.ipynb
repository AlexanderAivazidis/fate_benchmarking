{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e436e763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "from scvi.module.base import PyroBaseModuleClass\n",
    "from scvi.train import PyroTrainingPlan\n",
    "from typing import Optional, Union\n",
    "import pyro\n",
    "\n",
    "max_epochs = 4000\n",
    "start_lr = 0.01\n",
    "final_lr = 0.001\n",
    "lrd = (final_lr/start_lr)**(1/max_epochs)\n",
    "clipped_adam = pyro.optim.ClippedAdam({\"lr\": start_lr, \"lrd\": lrd,  \"clip_norm\": 10.0})\n",
    "\n",
    "class PyroTrainingPlan_ClippedAdamDecayingRate(PyroTrainingPlan):\n",
    "    \"\"\"\n",
    "    Lightning module task to train Pyro scvi-tools modules.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pyro_module\n",
    "        An instance of :class:`~scvi.module.base.PyroBaseModuleClass`. This object\n",
    "        should have callable `model` and `guide` attributes or methods.\n",
    "    loss_fn\n",
    "        A Pyro loss. Should be a subclass of :class:`~pyro.infer.ELBO`.\n",
    "        If `None`, defaults to :class:`~pyro.infer.Trace_ELBO`.\n",
    "    optim\n",
    "        A Pyro optimizer instance, e.g., :class:`~pyro.optim.Adam`. If `None`,\n",
    "        defaults to :class:`pyro.optim.Adam` optimizer with a learning rate of `1e-3`.\n",
    "    optim_kwargs\n",
    "        Keyword arguments for **default** optimiser :class:`pyro.optim.Adam`.\n",
    "    n_aggressive_epochs\n",
    "        Number of epochs in aggressive optimisation of amortised variables.\n",
    "    n_aggressive_steps\n",
    "        Number of steps to spend optimising amortised variables before one step optimising global variables.\n",
    "    n_steps_kl_warmup\n",
    "        Number of training steps (minibatches) to scale weight on KL divergences from 0 to 1.\n",
    "        Only activated when `n_epochs_kl_warmup` is set to None.\n",
    "    n_epochs_kl_warmup\n",
    "        Number of epochs to scale weight on KL divergences from 0 to 1.\n",
    "        Overrides `n_steps_kl_warmup` when both are not `None`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pyro_module: PyroBaseModuleClass,\n",
    "        loss_fn: Optional[pyro.infer.ELBO] = None,\n",
    "        optim: Optional[pyro.optim.PyroOptim] = clipped_adam,\n",
    "        optim_kwargs: Optional[dict] = None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            pyro_module=pyro_module,\n",
    "            loss_fn=loss_fn,\n",
    "            optim=optim,\n",
    "            optim_kwargs=optim_kwargs\n",
    "        )\n",
    "\n",
    "        self.svi = pyro.infer.SVI(\n",
    "            model=pyro_module.model,\n",
    "            guide=pyro_module.guide,\n",
    "            optim=self.optim,\n",
    "            loss=self.loss_fn,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5023c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Running UniTVelo 0.2.5.2)\n",
      "2023-11-26 12:22:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 12:22:32.400998: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-26 12:22:32.401373: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-26 12:22:32.558529: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "3\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.chdir('..')\n",
    "import scvelo as scv\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "scvi.settings.seed = 1\n",
    "import cell2fate as c2f\n",
    "import pickle as pickle\n",
    "from eval_utils import cross_boundary_correctness\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import unitvelo as utv\n",
    "method = 'Cell2fateDynamicalModel_pyroVelocityTrainingPlan'\n",
    "data_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_datasets/'\n",
    "save_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_results/'\n",
    "datasets = ['Pancreas_with_cc',  'DentateGyrus' , 'MouseBoneMarrow', 'MouseErythroid', 'HumanBoneMarrow']\n",
    "n_genes_list = np.array((2000, 3000))\n",
    "n_counts_list = np.array((10, 20))\n",
    "\n",
    "for i in range(len(n_genes_list)):\n",
    "    for j in range(len(n_counts_list)):\n",
    "        for k in (2,0,1,3,4):\n",
    "            print(i)\n",
    "            print(j)\n",
    "            print(k)\n",
    "            dataset = datasets[k]\n",
    "            n_genes = n_genes_list[i]\n",
    "            min_counts = n_counts_list[j]\n",
    "            model_index = str(i) + '-' + str(j) + '-' + str(k)\n",
    "            save_name = method + '_'\n",
    "            if exists(save_dir + save_name + '_CBDC_fullBenchmark.csv'):\n",
    "                tab = pd.read_csv(save_dir + save_name + '_CBDC_fullBenchmark.csv', index_col = 0)\n",
    "                if model_index in tab.index:\n",
    "                    continue\n",
    "            adata = sc.read_h5ad(data_dir + dataset + '/' + dataset + '_anndata.h5ad')\n",
    "            adata = c2f.utils.get_training_data(adata, cells_per_cluster = 10**6, cluster_column = 'clusters',\n",
    "                                            remove_clusters = [], min_shared_counts = min_counts, n_var_genes= n_genes)\n",
    "            c2f.Cell2fate_DynamicalModel.setup_anndata(adata, spliced_label='spliced', unspliced_label='unspliced')    \n",
    "            n_modules = c2f.utils.get_max_modules(adata)\n",
    "            mod = c2f.Cell2fate_DynamicalModel(adata,\n",
    "                                               n_modules = n_modules)\n",
    "            mod.train(max_epochs = 4000, **{'training_plan' : PyroTrainingPlan_ClippedAdamDecayingRate},\n",
    "                     early_stopping = True, early_stopping_min_delta = 10**(-4),\n",
    "                     early_stopping_monitor = 'elbo_train', early_stopping_patience = 45)\n",
    "            sample_kwarg = {\"num_samples\": 10, \"batch_size\" : adata.n_obs,\n",
    "                 \"use_gpu\" : True, 'return_samples': False}\n",
    "            adata = mod.export_posterior(adata, sample_kwargs = sample_kwarg)\n",
    "            mod.compute_and_plot_total_velocity_scvelo(adata, save = False, delete = False)\n",
    "            # Calculate performance metrics:\n",
    "            file = open(data_dir + dataset + '/' + dataset + '_groundTruth.pickle' ,'rb')\n",
    "            ground_truth = pickle.load(file)\n",
    "            metrics = utv.evaluate(adata, ground_truth, 'clusters', 'velocity')\n",
    "            cb_score = [np.mean(metrics['Cross-Boundary Direction Correctness (A->B)'][x])\n",
    "                        for x in metrics['Cross-Boundary Direction Correctness (A->B)'].keys()]\n",
    "            if exists(save_dir + save_name + '_CBDC_fullBenchmark.csv'):\n",
    "                tab = pd.read_csv(save_dir + save_name + '_CBDC_fullBenchmark.csv', index_col = 0)\n",
    "            else:\n",
    "                c_names = ['CBDC']\n",
    "                tab = pd.DataFrame(columns = c_names)\n",
    "            tab.loc[model_index, 'CBDC'] = np.mean(cb_score)\n",
    "            tab.to_csv(save_dir + save_name + '_CBDC_fullBenchmark.csv')\n",
    "tab = pd.read_csv(save_dir + save_name + '_CBDC_fullBenchmark.csv', index_col = 0)\n",
    "tab.loc['AVERAGE', 'CBDC'] = np.mean(tab['CBDC'])\n",
    "tab.to_csv(save_dir + save_name + '_CBDC_fullBenchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42097d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cell2fate_env]",
   "language": "python",
   "name": "conda-env-cell2fate_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
