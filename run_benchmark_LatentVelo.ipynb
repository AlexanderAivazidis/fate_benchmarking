{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f069efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Running UniTVelo 0.2.5)\n",
      "2022-12-21 13:16:32\n"
     ]
    }
   ],
   "source": [
    "import anndata\n",
    "import numpy as np\n",
    "import scvelo as scv\n",
    "import scanpy as sc\n",
    "import sys\n",
    "import torch\n",
    "import os.path\n",
    "import deepvelo as dv\n",
    "import pickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import unitvelo as utv\n",
    "from os.path import exists\n",
    "method = 'DeepVelo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc431cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['HumanDevelopingBrain', 'Pancreas_with_cc', 'DentateGyrus' , 'MouseBoneMarrow', 'MouseErythroid', 'HumanBoneMarrow']\n",
    "data_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_datasets/'\n",
    "save_dir = '/nfs/team283/aa16/data/fate_benchmarking/benchmarking_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c86cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanBoneMarrow\n",
      "Filtered out 7837 genes that are detected 20 counts (shared).\n",
      "Normalized count data: X, spliced, unspliced.\n",
      "Extracted 3000 highly variable genes.\n",
      "Logarithmized X.\n",
      "computing neighbors\n",
      "    finished (0:00:07) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:01) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "Config Warning: Set to use GPU, but GPU version of DGL is not installed. Reset to use CPU instead.\n",
      "Warning: logging configuration file is not found in logger/logger_config.json.\n",
      "building graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:Beginning training of DeepVelo_Base ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "velo data shape: torch.Size([5780, 3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/team283/aa16/software/miniconda3/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/nfs/team283/aa16/software/miniconda3/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ) < LooseVersion(\"1.15\"):\n",
      "INFO:trainer:    epoch          : 1\n",
      "INFO:trainer:    time:          : 15.600116729736328\n",
      "INFO:trainer:    loss           : 97965.7109375\n",
      "INFO:trainer:    mse            : 0.03537687286734581\n",
      "INFO:trainer:    epoch          : 2\n",
      "INFO:trainer:    time:          : 15.767579078674316\n",
      "INFO:trainer:    loss           : 12758.89453125\n",
      "INFO:trainer:    mse            : 0.05043487995862961\n",
      "INFO:trainer:    epoch          : 3\n",
      "INFO:trainer:    time:          : 15.725565671920776\n",
      "INFO:trainer:    loss           : 6970.35009765625\n",
      "INFO:trainer:    mse            : 0.07707884162664413\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    adata = sc.read_h5ad(data_dir + dataset + '/' + dataset + '_anndata.h5ad')\n",
    "    scv.pp.filter_and_normalize(adata, min_shared_counts=20, n_top_genes=3000)\n",
    "    scv.pp.moments(adata, n_pcs=30, n_neighbors=30)\n",
    "    trainer = dv.train(adata, dv.Constants.default_configs)\n",
    "    scv.pp.neighbors(adata)\n",
    "    scv.tl.velocity_graph(adata, vkey = 'velocity')\n",
    "    scv.tl.velocity_embedding(adata, vkey = 'velocity')\n",
    "    fix, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
    "    scv.pl.velocity_embedding_stream(adata, basis='umap', save = False, vkey='velocity',\n",
    "                                     show = False, ax = ax)\n",
    "    plt.savefig(save_dir + 'UMAPs/' + dataset + '_UMAP_DeepVelo.png')\n",
    "    # Calculate performance metrics:\n",
    "    file = open(data_dir + dataset + '/' + dataset + '_groundTruth.pickle' ,'rb')\n",
    "    ground_truth = pickle.load(file)\n",
    "    metrics = utv.evaluate(adata, ground_truth, 'clusters', 'velocity')\n",
    "    if exists(save_dir + dataset + '_CBDC_scores.csv'):\n",
    "        tab = pd.read_csv(save_dir + dataset + '_CBDC_scores.csv', index_col = 0)\n",
    "    else:\n",
    "        tab = pd.DataFrame(columns = list(metrics['Cross-Boundary Direction Correctness (A->B)'].keys()) + ['Mean'],\n",
    "                 index = [method])\n",
    "    cb_score = [np.mean(metrics['Cross-Boundary Direction Correctness (A->B)'][x])\n",
    "                for x in metrics['Cross-Boundary Direction Correctness (A->B)'].keys()]\n",
    "    tab.loc[method,:] = cb_score + [np.mean(cb_score)]\n",
    "    tab.to_csv(save_dir + dataset + '_CBDC_scores.csv')\n",
    "    metrics = utv.evaluate(adata, ground_truth, 'clusters', 'velocity')\n",
    "    if exists(save_dir + dataset + '_ICC_scores.csv'):\n",
    "        tab = pd.read_csv(save_dir + dataset + '_ICC_scores.csv', index_col = 0)\n",
    "    else:\n",
    "        tab = pd.DataFrame(columns = list(np.unique(np.concatenate(ground_truth))) + ['Mean'],\n",
    "                 index = [method])\n",
    "    icc_score = [np.mean(metrics['In-cluster Coherence'][x]) for x in np.unique(np.concatenate(ground_truth))]\n",
    "    tab.loc[method,:] = icc_score + [np.mean(icc_score)]\n",
    "    tab.to_csv(save_dir + dataset + '_ICC_scores.csv')\n",
    "    fix, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
    "    scv.pl.velocity_embedding_stream(adata, basis='umap', save = False, vkey='velocity',\n",
    "                                     show = False, ax = ax)\n",
    "    plt.savefig(save_dir + 'UMAPs/' + dataset + '_UMAP_' + method + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96cb98c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
